{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded0783b",
   "metadata": {},
   "source": [
    "# The objective of this worksheet is to explore and apply Pyspark Data Frame operations to deal with missing values, filtering data, grouping data and joining data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('DataFrames-Worksheet-2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ebc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df =spark.read.csv('StudentData-1.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed677b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba94ea",
   "metadata": {},
   "source": [
    "# Deleting all rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is your observation about the above output?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2367e",
   "metadata": {},
   "source": [
    "# Deleting rows with null value in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ee832",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.drop(how = 'any').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35817278",
   "metadata": {},
   "source": [
    "# Deleting rows with null value in a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c041e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.drop(how=\"any\",subset=['Marks']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36845e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do yourself: Check 'how = all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34afb685",
   "metadata": {},
   "source": [
    "## Deleting rows with a certain number of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.drop(how='any', thresh = 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.drop(how='any', thresh = 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787fc949",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.drop(thresh = 4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc1480",
   "metadata": {},
   "source": [
    "## Replacing null values with a particular value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bad9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.fill(50,['Marks']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.fill('Good', subset = ['Comments']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846cbc1f",
   "metadata": {},
   "source": [
    "## Replacing null value with mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e01bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_marks = s_df.select(mean('Marks')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce135af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.fill(mean_marks,'Marks').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33377935",
   "metadata": {},
   "source": [
    "## Replacing null value with particular values in multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f577ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.na.fill({'Marks': mean_marks, 'Attendance':80, 'Comments': 'V. Good'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87828f7a",
   "metadata": {},
   "source": [
    "## Applying Filters: filter on a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.filter('Marks >= 80').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do yourself: Display only students' name and marks with more than 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd8992",
   "metadata": {},
   "source": [
    "## Filtering using more than one columns: Display students with more than 80% marks and more than 90% attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fd913",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.filter((s_df['Marks'] > 80) & (s_df['Attendance'] > 90)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2c293",
   "metadata": {},
   "source": [
    "## Filtering using more than one columns: Display students with more than 80% marks and Excellent comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835812ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.filter((s_df['Marks'] > 80) & (s_df['Comments'] == 'Excellent')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b313f03",
   "metadata": {},
   "source": [
    "## Filtering using more than one columns: Display students with more than 80% marks and no null value in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9696ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.filter((s_df['Marks'] > 80) & ~(s_df['Comments'] == 'null')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3ad3a",
   "metadata": {},
   "source": [
    "## Applying GroupBy method: Group traffic data by region using 'sum' as aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Traffic = spark.read.csv('Traffic_Data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6214f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Traffic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Traffic.groupBy('Region').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e980e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating based on a specific column\n",
    "df_Traffic.groupBy('Region').sum('Count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Traffic.groupBy('Region').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c34ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by using multiple columns\n",
    "\n",
    "df_Traffic.groupBy('Region', 'Year').sum('Count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de076f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Traffic.groupBy('Region').sum('Count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a190554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Traffic.groupBy('Region').mean('Count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927106ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do yourself: Group traffic data by region, year and traffic type using 'count', 'mean', 'min' and  'avg' as aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd44a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266850f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e755760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa50870f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aaf8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f2963d",
   "metadata": {},
   "source": [
    "## Applying Aggregation: Finding average traffic count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea370703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Traffic.agg({'Count':'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0ee9c",
   "metadata": {},
   "source": [
    "## Applying Aggregation: Finding average of year and traffic count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3067b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Traffic.agg({'Year': 'mean', 'Count':'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb316ea",
   "metadata": {},
   "source": [
    "## Formatting the output. \n",
    "\n",
    "### - To round the mean values for both Year and Count columns in your PySpark DataFrame, you can use the round function from pyspark.sql.functions. Since the .agg() method with a dictionary does not directly allow applying additional functions like round, youâ€™ll need to use select with explicit rounding for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76447918",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = df_Traffic.agg(f.mean(\"Year\").alias(\"mean_Year\"), f.mean(\"Count\").alias(\"mean_Count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e87a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mean_df.select(f.round(\"mean_Year\", 2).alias(\"mean_Year\"), f.round(\"mean_Count\", 2).alias(\"mean_Count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e505bcaf",
   "metadata": {},
   "source": [
    "# Applying Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e71485",
   "metadata": {},
   "source": [
    "## Creating two new Spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97659c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A =spark.read.csv('StudentData-3.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd0e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B =spark.read.csv('StudentData-4.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ad856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = df_A.join(df_B, on=\"ID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bdb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do yourself: apply right, inner and full join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34e84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0f720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5142332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a505c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c07c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b983d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56545c35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e258e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2e92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a574166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
